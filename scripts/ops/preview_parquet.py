"""
Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python scripts/ops/preview_parquet.py <parquet_file_path> [--rows N] [--columns COL1,COL2,...]
    
ä¾‹:
    python scripts/ops/preview_parquet.py data/processed/index_tpx_daily.parquet
    python scripts/ops/preview_parquet.py data/processed/paper_trade_with_alpha_beta.parquet --rows 20
    python scripts/ops/preview_parquet.py data/processed/paper_trade_with_alpha_beta.parquet --columns trade_date,port_ret_cc,alpha_ret_cc
"""
import argparse
import sys
from pathlib import Path
from typing import List, Optional

import pandas as pd


def preview_parquet(
    file_path: Path,
    n_rows: int = 10,
    columns: Optional[List[str]] = None,
    show_info: bool = True,
) -> None:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¡¨ç¤º"""
    if not file_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}", file=sys.stderr)
        sys.exit(1)

    try:
        df = pd.read_parquet(file_path)
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        sys.exit(1)

    if df.empty:
        print("âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç©ºã§ã™")
        return

    # åŸºæœ¬æƒ…å ±
    if show_info:
        print("=" * 80)
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
        print(f"ğŸ“Š è¡Œæ•°: {len(df):,}")
        print(f"ğŸ“‹ åˆ—æ•°: {len(df.columns)}")
        print(f"ğŸ“… æ—¥ä»˜ç¯„å›²: ", end="")
        
        # æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’æ¢ã™
        date_cols = [c for c in df.columns if "date" in c.lower() or "time" in c.lower()]
        if date_cols:
            date_col = date_cols[0]
            if pd.api.types.is_datetime64_any_dtype(df[date_col]):
                print(f"{df[date_col].min()} ï½ {df[date_col].max()}")
            else:
                print("(æ—¥ä»˜ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        else:
            print("(æ—¥ä»˜ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
        print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")
        print("=" * 80)
        print()

    # ã‚«ãƒ©ãƒ æƒ…å ±
    if show_info:
        print("ğŸ“‹ ã‚«ãƒ©ãƒ ä¸€è¦§:")
        for i, col in enumerate(df.columns, 1):
            dtype = df[col].dtype
            null_count = df[col].isna().sum()
            null_pct = (null_count / len(df)) * 100
            print(f"  {i:2d}. {col:30s} ({dtype}) - NaN: {null_count:,} ({null_pct:.1f}%)")
        print()

    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
    print("-" * 80)
    
    # è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
    display_df = df.copy()
    if columns:
        # æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ã¿è¡¨ç¤º
        missing_cols = [c for c in columns if c not in df.columns]
        if missing_cols:
            print(f"âš ï¸  æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}", file=sys.stderr)
        display_cols = [c for c in columns if c in df.columns]
        if display_cols:
            display_df = display_df[display_cols]
        else:
            print("âš ï¸  è¡¨ç¤ºå¯èƒ½ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ã‚«ãƒ©ãƒ ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚", file=sys.stderr)
            display_cols = None
    else:
        display_cols = None

    # å…ˆé ­
    print(f"\nã€å…ˆé ­ {min(n_rows, len(df))} è¡Œã€‘")
    pd.set_option("display.max_columns", None)
    pd.set_option("display.width", None)
    pd.set_option("display.max_colwidth", 50)
    print(display_df.head(n_rows).to_string())
    
    # æœ«å°¾ï¼ˆè¡Œæ•°ãŒå¤šã„å ´åˆï¼‰
    if len(df) > n_rows * 2:
        print(f"\nã€æœ«å°¾ {min(n_rows, len(df))} è¡Œã€‘")
        print(display_df.tail(n_rows).to_string())
    
    # çµ±è¨ˆæƒ…å ±ï¼ˆæ•°å€¤ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
    numeric_cols = display_df.select_dtypes(include=["number"]).columns.tolist()
    if numeric_cols and show_info:
        print(f"\nğŸ“ˆ çµ±è¨ˆæƒ…å ±ï¼ˆæ•°å€¤ã‚«ãƒ©ãƒ ï¼‰:")
        print("-" * 80)
        stats = display_df[numeric_cols].describe()
        print(stats.to_string())

    print()
    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¾‹:
  %(prog)s data/processed/index_tpx_daily.parquet
  %(prog)s data/processed/paper_trade_with_alpha_beta.parquet --rows 20
  %(prog)s data/processed/paper_trade_with_alpha_beta.parquet --columns trade_date,port_ret_cc,alpha_ret_cc
        """,
    )
    parser.add_argument(
        "file_path",
        type=str,
        help="ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹",
    )
    parser.add_argument(
        "--rows",
        type=int,
        default=10,
        help="è¡¨ç¤ºã™ã‚‹è¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰",
    )
    parser.add_argument(
        "--columns",
        type=str,
        default=None,
        help="è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: col1,col2,col3ï¼‰",
    )
    parser.add_argument(
        "--no-info",
        action="store_true",
        help="åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤ºã—ãªã„",
    )

    args = parser.parse_args()

    file_path = Path(args.file_path)
    columns = args.columns.split(",") if args.columns else None
    if columns:
        columns = [c.strip() for c in columns]

    preview_parquet(
        file_path=file_path,
        n_rows=args.rows,
        columns=columns,
        show_info=not args.no_info,
    )


if __name__ == "__main__":
    main()

